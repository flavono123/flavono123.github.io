<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>linux on flavono123</title><link>https://flavono123.github.io/tags/linux/</link><description>Recent content in linux on flavono123</description><generator>Hugo -- gohugo.io</generator><language>ko-kr</language><lastBuildDate>Thu, 15 Sep 2022 10:28:13 +0900</lastBuildDate><atom:link href="https://flavono123.github.io/tags/linux/index.xml" rel="self" type="application/rss+xml"/><item><title>Ansible에서 unprivileged become_user 실패</title><link>https://flavono123.github.io/posts/ansible-needs-to-create-when-becoming-an-unprivileged-user/</link><pubDate>Thu, 15 Sep 2022 10:28:13 +0900</pubDate><guid>https://flavono123.github.io/posts/ansible-needs-to-create-when-becoming-an-unprivileged-user/</guid><description>Ansible 태스크에서 become: yes를 사용해 sudo처럼 루트 권한으로 명령을 실행한다. 예를 들면 Ubuntu에서 apt 패키지를 쓸 때 사용할 수 있다. 하지만 루트가 아닌 특정 사용자로 실행해야 하는 명령도 있다. 최근에 MaxScale을 2.5 버전으로 업그레이드 했는데, 구성 확인 명령이 이전과 달리 maxscale 사용자만 실행할 수 있도록 강제하고 있다:
$ whoami ubuntu $ maxscale --config-check info : MaxScale will be run in the terminal process. 2022-09-15 10:34:01 notice : Worker message queue size: 1MiB 2022-09-15 10:34:01 warning: Number of threads set to 8, which is greater than the number of processors available: 1 2022-09-15 10:34:01 warning: Number of threads set to 8, which is greater than the number of processors available: 1 2022-09-15 10:34:01 notice : Using up to 296.</description></item><item><title>Kubestr</title><link>https://flavono123.github.io/posts/kubestr-and-monitoring-tools/</link><pubDate>Mon, 30 May 2022 23:24:25 +0900</pubDate><guid>https://flavono123.github.io/posts/kubestr-and-monitoring-tools/</guid><description>kubestr라는 쿠버네티스 저장소 IO 벤치마크 도구로 저장소 성능을 측정해본다. 지난 글에서 만든 local-path-provisioner와 nfs-subdir-external-provisioner를 새로 설치해 둘을 비교한다. 로컬 VM에서 하는 것이기 때문에 실제 성능 측정보단 벤치마크 자체를 연습해본다. 또 벤치마킹하는 동안 컴퓨팅 자원 지표를 측정할 수 있는 모니터 도구 sar를 사용해본다.
NFS nfs-subdir-external-provisioner를 설치하기 위해 노드에 NFS를 마운트한다. 별도 NFS 노드를 준비하지 않고 controlplane에 마운트한다:
--- # variables nfs_mount_path: /nfs-storage nfs_network_cidr: 192.168.1.0/24 --- # tasks - name: Turn up NFS in controlplane become: yes block: - name: Install nfs-kernel-server apt: state: present update_cache: yes name: - nfs-kernel-server - name: Create NFS mount path file: state: directory owner: nobody group: nogroup mode: &amp;#34;0777&amp;#34; path: &amp;#34;{{ nfs_mount_path }}&amp;#34; - name: Add exports table to /etc/exports blockinfile: path: /etc/exports block: | {{ nfs_mount_path }} {{ nfs_network_cidr }}(rw,sync,no_subtree_check) - name: Export /etc/exports command: exportfs -a - name: Restart nfs-kernel-server service command: systemctl restart nfs-kernel-server when: - &amp;#34;&amp;#39;controlplane&amp;#39; in group_names&amp;#34; - name: Install nfs-client become: yes apt: state: present update_cache: yes name: - nfs-common controlplane엔:</description></item><item><title>ip: 리눅스 네트워크 장치</title><link>https://flavono123.github.io/posts/get-net-dev-from-ip/</link><pubDate>Sun, 06 Mar 2022 00:03:41 +0900</pubDate><guid>https://flavono123.github.io/posts/get-net-dev-from-ip/</guid><description>리눅스에서 ip 명령을 통해 네트워크 장치를 확인하고 구성할 수 있다. 그런데 이더넷 카드 이름이 언젠가부터(?) eth*가 아닌 enp*s*로 나오고 있다. &amp;lsquo;언젠가&amp;rsquo;는 리눅스를 VMWare에 처음 설치해봤던 학생 때이고 지금은 시간이 많이 지났다. eth는 이더넷이란 이름에 찰싹 달라 붙어 받아 들였지만, eno* 또는 enp*s* 역시 이더넷 카드를 뜻하는건지 궁금해졌다. 이번에도 알게 된 점 그리고 모르기로 한 부분을 나눠 정리한다.
Predictable Network Interface Names 위 같은 변화는 systemd가 나오며 시작됐다(정확하게는 v197라는 배포판에서 이다). 과거엔 간단하게 eth 뒤에 인덱스를 붙여도 드라이버가 찾을 수 있었지만, 오늘 날의 네트워크 구성 기술에선 이름을 쉽게 바꿀 수 있고 같은 이름으로도 여러 곳에서 사용할 수 있어 적합하지 않다고 한다.</description></item><item><title>CKA 시험 후기와 Security Context - 리눅스 네임스페이스, capabilities</title><link>https://flavono123.github.io/posts/cka-security-context/</link><pubDate>Fri, 25 Feb 2022 18:24:34 +0900</pubDate><guid>https://flavono123.github.io/posts/cka-security-context/</guid><description>이전까지 쓰던 CKA 강의 정리 글을 중단하고, 남은 섹션 빠르게 공부한 후, 합격했다&amp;hellip;
인터넷에 보면 시험 (합격)후기 글이 많다. 시험 팁과 관련된 내용이 주로 있고 나도 그런 글 도움을 많이 받았다. 하지만 나는 조금 다른 이야길 해보려 한다.
우선 강의와 더불어 시험을 보는 과정에서 배우는 것들이 좋았다. 어찌보면 난 컨테이너(도커)는 아주 깔짝, 리눅스도 깔짝 알고 있는 수준이었다는게 드러났다. 예컨데 나는 리눅스 네트워크는 꽤 잘 안다고 착각했다. 이유는 (지금 생각하면 조금 어이 없지만) on-premise 호스트에서 DHCP를 쓰지 않고 정적으로 IP를 할당했기 때문에 그렇다고 생각했다.</description></item></channel></rss>